{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import yaml\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from  torch import nn\n",
    "import mediapipe as mp\n",
    "from torch import optim\n",
    "from datetime import datetime\n",
    "from torchmetrics import Accuracy\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetWork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NeuralNetWork,self).__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        list_label = label_dict_from_config_file(\"hand_gesture.yaml\")\n",
    "\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            nn.Linear(63,128),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.Linear(128,128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(p=0.4),\n",
    "            nn.Linear(128,128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(p=0.4),\n",
    "            nn.Linear(128,128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(p=0.6),\n",
    "            nn.Linear(128,len(list_label)),\n",
    "        ) \n",
    "\n",
    "    def forward(self,x):\n",
    "        x = self.flatten(x)\n",
    "        x = self.linear_relu_stack(x)\n",
    "        return x\n",
    "    def predict(self,x,threshold=0.8):\n",
    "        logits = self(x)\n",
    "        softmax_prob = nn.Softmax(dim=1)(logits)\n",
    "        chosen_ind = torch.argmax(softmax_prob,dim=1)\n",
    "        return torch.where(softmax_prob[0,chosen_ind]>threshold,chosen_ind,-1)\n",
    "\n",
    "    def predict_with_known_class(self,x):\n",
    "        logits = self(x)\n",
    "        softmax_prob = nn.Softmax(dim=1)(logits)\n",
    "        return torch.argmax(softmax_prob,dim=1)\n",
    "\n",
    "    def score(self,logits):\n",
    "        return -torch.amax(logits,dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_dict_from_config_file(relative_path):\n",
    "    with open(relative_path,\"r\") as f:\n",
    "        label_tag = yaml.full_load(f)[\"gestures\"]\n",
    "    return label_tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HandLandmarksDetector():\n",
    "    def __init__(self) -> None:\n",
    "        self.mp_drawing = mp.solutions.drawing_utils\n",
    "        self.mp_drawing_styles = mp.solutions.drawing_styles\n",
    "        self.mp_hands = mp.solutions.hands\n",
    "        self.detector = self.mp_hands.Hands(False,max_num_hands=1,min_detection_confidence=0.5)\n",
    "\n",
    "    def detectHand(self,frame):\n",
    "        hands = []\n",
    "        frame = cv2.flip(frame, 1)\n",
    "        annotated_image = frame.copy()\n",
    "        results = self.detector.process(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))\n",
    "        if results.multi_hand_landmarks is not None:\n",
    "            for hand_landmarks in results.multi_hand_landmarks:\n",
    "                hand = []\n",
    "                self.mp_drawing.draw_landmarks(\n",
    "                    annotated_image,\n",
    "                    hand_landmarks,\n",
    "                    self.mp_hands.HAND_CONNECTIONS,\n",
    "                    self.mp_drawing_styles.get_default_hand_landmarks_style(),\n",
    "                    self.mp_drawing_styles.get_default_hand_connections_style())\n",
    "                for landmark in hand_landmarks.landmark:\n",
    "                    x,y,z = landmark.x,landmark.y,landmark.z\n",
    "                    hand.extend([x,y,z])\n",
    "            hands.append(hand)\n",
    "        return hands,annotated_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomImageDataset(Dataset):\n",
    "    def __init__(self, data_file):\n",
    "        self.data = pd.read_csv(data_file)\n",
    "        self.labels = torch.from_numpy(self.data.iloc[:,0].to_numpy())\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        one_hot_label = self.labels[idx]\n",
    "        torch_data = torch.from_numpy(self.data.iloc[idx,1:].to_numpy(dtype=np.float32))\n",
    "        return torch_data, one_hot_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EarlyStopper:\n",
    "    def __init__(self, patience=1, min_delta=0):\n",
    "        self.patience = patience\n",
    "        self.min_delta = min_delta\n",
    "        self.counter = 0\n",
    "        self.watched_metrics = np.inf\n",
    "\n",
    "    def early_stop(self, current_value):\n",
    "        if current_value < self.watched_metrics:\n",
    "            self.watched_metrics = current_value\n",
    "            self.counter = 0\n",
    "        elif current_value > (self.watched_metrics + self.min_delta):\n",
    "            self.counter += 1\n",
    "            if self.counter >= self.patience:\n",
    "                return True\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(trainloader, val_loader, model, loss_function, early_stopper, optimizer):\n",
    "    # add auroc score\n",
    "    best_vloss = 1_000_000\n",
    "    timestamp = datetime.now().strftime('%d-%m %H:%M')\n",
    "    for epoch in range(300):\n",
    "        #training step\n",
    "        model.train(True)\n",
    "        running_loss = 0.0\n",
    "        acc_train = Accuracy(num_classes=len(LIST_LABEL), task='MULTICLASS')\n",
    "        for batch_number,data in enumerate(trainloader):\n",
    "            inputs, labels = data\n",
    "            optimizer.zero_grad()\n",
    "            preds = model(inputs) \n",
    "            loss = loss_function(preds, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            acc_train.update(model.predict_with_known_class(inputs), labels)\n",
    "            running_loss += loss.item()\n",
    "        avg_loss = running_loss / len(trainloader)\n",
    "        # validating step\n",
    "        model.train(False)\n",
    "        running_vloss = 0.0\n",
    "        acc_val = Accuracy(num_classes=len(LIST_LABEL), task='MULTICLASS')\n",
    "        for i, vdata in enumerate(val_loader):\n",
    "            vinputs, vlabels = vdata\n",
    "            preds = model(vinputs)\n",
    "            vloss = loss_function(preds, vlabels)\n",
    "            running_vloss += vloss.item()\n",
    "            acc_val.update(model.predict_with_known_class(vinputs), vlabels)\n",
    "\n",
    "        # Log the running loss averaged per batch\n",
    "        # for both training and validation\n",
    "        print(f\"Epoch {epoch}: \")\n",
    "        print(f\"Accuracy train:{acc_train.compute().item()}, val:{acc_val.compute().item()}\")\n",
    "        avg_vloss = running_vloss / len(val_loader)\n",
    "        print('LOSS train {} valid {}'.format(avg_loss, avg_vloss))\n",
    "        print('Training vs. Validation Loss',\n",
    "                        { 'Training' : avg_loss, 'Validation' : avg_vloss },\n",
    "                        epoch + 1)\n",
    "        print('Training vs. Validation accuracy',\n",
    "                        { 'Training' : acc_train.compute().item()\n",
    "                        , 'Validation' : acc_val.compute().item() },\n",
    "                        epoch + 1)\n",
    "\n",
    "        # Track best performance, and save the model's state\n",
    "        if avg_vloss < best_vloss:\n",
    "            best_vloss = avg_vloss\n",
    "            best_model_path = f'./{save_path}/model_{timestamp}_{model.__class__.__name__}_best'\n",
    "            torch.save(model.state_dict(), best_model_path)\n",
    "\n",
    "        if early_stopper.early_stop(avg_vloss):\n",
    "            print(f\"Stopping at epoch {epoch + 1}, minimum watched metric: {best_vloss:.4f}\")\n",
    "            break\n",
    "\n",
    "    model_path = f'./{save_path}/model_{timestamp}_{model.__class__.__name__}_last'\n",
    "    torch.save(model.state_dict(), model_path)\n",
    "\n",
    "    print(acc_val.compute())\n",
    "    return model, best_model_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_FOLDER_PATH=\"./data2/\"\n",
    "LIST_LABEL = label_dict_from_config_file(\"hand_gesture.yaml\")\n",
    "train_path = os.path.join(DATA_FOLDER_PATH,\"landmark_train.csv\")\n",
    "val_path = os.path.join(DATA_FOLDER_PATH,\"landmark_val.csv\")\n",
    "save_path = './models'\n",
    "os.makedirs(save_path,exist_ok=True)\n",
    "\n",
    "trainset = CustomImageDataset(train_path)\n",
    "trainloader = DataLoader(trainset,batch_size=40,shuffle=True)\n",
    "\n",
    "valset = CustomImageDataset(os.path.join(val_path))\n",
    "val_loader = DataLoader(valset,batch_size=50, shuffle=False)\n",
    "\n",
    "model = NeuralNetWork()\n",
    "loss_function = nn.CrossEntropyLoss()\n",
    "early_stopper = EarlyStopper(patience=30,min_delta=0.01)\n",
    "optimizer = optim.Adam(model.parameters(),lr=0.0001)\n",
    "\n",
    "model, best_model_path = train(trainloader, val_loader, model, loss_function, early_stopper, optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_label = label_dict_from_config_file(\"hand_gesture.yaml\")\n",
    "DATA_FOLDER_PATH=\"./data/\"\n",
    "testset = CustomImageDataset(os.path.join(DATA_FOLDER_PATH,\"landmark_test.csv\"))\n",
    "test_loader = torch.utils.data.DataLoader(testset,batch_size=20,shuffle=False)\n",
    "\n",
    "network = NeuralNetWork()\n",
    "network.load_state_dict(torch.load(best_model_path, weights_only=False))\n",
    "\n",
    "network.eval()\n",
    "acc_test = Accuracy(num_classes=len(list_label), task='MULTICLASS')\n",
    "for i, test_data in enumerate(test_loader):\n",
    "    test_input, test_label = test_data\n",
    "    preds = network(test_input)\n",
    "    acc_test.update(preds,test_label)\n",
    "\n",
    "print(network.__class__.__name__)\n",
    "print(f\"Accuracy of model:{acc_test.compute().item()}\")\n",
    "print(\"========================================================================\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
